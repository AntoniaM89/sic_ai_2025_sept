{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPFIakJg93P2DyMKg9LMZpo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidlealo/sic_ai_2025_sept/blob/main/3_machine_learning/contribuciones_estudiantes/ensayo_clase11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itldTS8GaHXd",
        "outputId": "02282f11-0012-4f0e-9c59-3b156010c7e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting kaggle\n",
            "  Downloading kaggle-1.7.4.5-py3-none-any.whl.metadata (16 kB)\n",
            "Downloading kaggle-1.7.4.5-py3-none-any.whl (181 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/181.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m174.1/181.2 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.2/181.2 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: kaggle\n",
            "  Attempting uninstall: kaggle\n",
            "    Found existing installation: kaggle 1.7.4.5\n",
            "    Uninstalling kaggle-1.7.4.5:\n",
            "      Successfully uninstalled kaggle-1.7.4.5\n",
            "Successfully installed kaggle-1.7.4.5\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade --force-reinstall --no-deps kaggle\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "id": "p8oi7KtTaZJA",
        "outputId": "dedb73a5-0275-49f0-825a-52991db7d9d7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0029ce8a-6b14-4770-99c3-6a7e2bb8c1f8\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0029ce8a-6b14-4770-99c3-6a7e2bb8c1f8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "D-KiWPjfaXDD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle models list\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xclpPlfRap0O",
        "outputId": "5b7ce253-5704-4d33-ac0c-753183a3239d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Next Page Token = CfDJ8EjpvNnYgNtGoWS2kk3rGCIzBGeuifZa3YjJqb2mj27l09fb_mOFlqAW5e8Ajpp1Z6wP2BJqY74nYVqLkmnKK-s\n",
            "    id  ref                                  title                     subtitle                                                                                                                                                                                                                                                  author          \n",
            "------  -----------------------------------  ------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------  --------------  \n",
            "446705  qwen-lm/qwen3-next-80b               Qwen3 Next 80B            Qwen3-Next-80B-A3B is the first installment in the Qwen3-Next series and features the following key enchancements like Hybrid Attention, High-Sparsity Mixture-of-Experts (MoE), Stability Optimizations and Multi-Token Prediction (MTP)                 QwenLM          \n",
            "164048  qwen-lm/qwen2.5                      Qwen2.5                   Qwen2.5 is the latest series of Qwen large language models. Qwen2.5 has a number of base language models and instruction-tuned language models ranging from 0.5 to 72 billion parameters.                                                                 QwenLM          \n",
            "437846  google/vaultgemma                    VaultGemma                VaultGemma is a variant of the Gemma family of lightweight, state-of-the-art open models from Google                                                                                                                                                      Google          \n",
            "443655  qaedtgyh/airs                        airs                                                                                                                                                                                                                                                                                V1ctorious3010  \n",
            "429004  yangjiahua/lora_14b_gptq_1epoch_r32  lora_14B_GPTQ_1epoch_r32                                                                                                                                                                                                                                                            YANGJIAHUA      \n",
            "443416  thangdoduc/fgs1                      fgs1                                                                                                                                                                                                                                                                                Thang Do        \n",
            "443413  thangdoduc/airs                      airs                                                                                                                                                                                                                                                                                Thang Do        \n",
            "  3301  google/gemma                         Gemma                     Gemma is a family of lightweight, open models built from the research and technology that Google used to create the Gemini models.                                                                                                                        Google          \n",
            "368803  qwen-lm/qwen-3-embedding             Qwen 3 Embedding          Qwen3 Embedding model is a proprietary model built for text embedding and ranking. It significantly improves performance across various tasks like text retrieval, code retrieval, text classification, text clustering, and bitext mining.               QwenLM          \n",
            "421107  google/embeddinggemma                EmbeddingGemma            EmbeddingGemma is a 300m parameter, state-of-the-art for its size, open embedding model from Google, built from Gemma 3 (with T5Gemma initialization) and the same research and technology used to create Gemini models.                                  Google          \n",
            "443656  qaedtgyh/fgs1                        fgs1                                                                                                                                                                                                                                                                                V1ctorious3010  \n",
            "322000  qwen-lm/qwen-3                       Qwen 3                    Qwen3 is the latest generation of large language models in Qwen series, offering a comprehensive suite of dense and mixture-of-experts (MoE) models.                                                                                                      QwenLM          \n",
            "407242  qwen-lm/qwen3-coder                  Qwen 3 Coder              Qwen 3 Coder is a specialized large language model designed for agentic coding and advanced long context understanding, supporting repository-scale comprehension                                                                                         QwenLM          \n",
            "  3533  keras/gemma                          Gemma                     Keras implementation of the Gemma model. This Keras 3 implementation will run on JAX, TensorFlow and PyTorch.                                                                                                                                             Keras           \n",
            "222398  google/gemma-3                       Gemma 3                   Gemma is a family of lightweight, state-of-the-art open models from Google, built from the same research and technology used to create the Gemini models.                                                                                                 Google          \n",
            "448093  keras/vaultgemma                     VaultGemma                Keras implementation of the VaultGemma model. Can run on JAX, TensorFlow and PyTorch.                                                                                                                                                                     Keras           \n",
            "400086  wasupandceacar/cmi-models-public     cmi-models-public                                                                                                                                                                                                                                                                   wasupandceacar  \n",
            "455967  openpeer-ai/openpeerllm              OpenPeerLLM               Distributed AI for the Massess                                                                                                                                                                                                                            OpenPeer AI     \n",
            "225262  deepseek-ai/deepseek-r1              DeepSeek R1               We introduce our first-generation reasoning models, DeepSeek-R1-Zero and DeepSeek-R1. DeepSeek-R1-Zero, a model trained via large-scale reinforcement learning (RL) without SFT as a preliminary step, demonstrated remarkable performance on reasoning.  DeepSeek        \n",
            "452134  mistral-ai/magistral-small-2509      Magistral Small 2509      Building upon Mistral Small 3.2 (2506), with added reasoning capabilities, undergoing SFT from Magistral Medium traces and RL on top, it's a small, efficient reasoning model with 24B parameters.                                                        Mistral AI      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets list -s Mobile-Price-Classification\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-FJ5bqBavvE",
        "outputId": "6a691ee7-9658-462c-f6c0-3a2756fb68b6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ref                                                               title                                                    size  lastUpdated                 downloadCount  voteCount  usabilityRating  \n",
            "----------------------------------------------------------------  -------------------------------------------------  ----------  --------------------------  -------------  ---------  ---------------  \n",
            "iabhishekofficial/mobile-price-classification                     Mobile Price Classification                             72340  2018-01-28 08:44:24.237000         235339       2402  0.7058824        \n",
            "jacksondivakarr/phone-classification-dataset                      Phone Classification Dataset                           210416  2023-12-12 15:21:07.330000           8222         91  1.0              \n",
            "mbsoroush/mobile-price-range                                      Mobile Price Range                                      72340  2024-07-29 08:05:56.637000           2342         43  1.0              \n",
            "parisanahmadi/mobilepriceclassification                           Mobile-Price-Classification                             72340  2022-07-20 23:48:47.747000            161          8  0.1764706        \n",
            "navjotkaushal/mobile-price-classification-dataset                 Mobile Price Classification Dataset                     58662  2025-08-29 07:17:16.100000             32          3  0.8235294        \n",
            "gauravduttakiit/mobile-price-classification                       Mobile Price Classification                             74269  2022-09-18 08:18:44.663000            229          1  0.3529412        \n",
            "sufyan145/mobile-price-classification                             Mobile Price Classification                             44257  2025-05-19 09:32:07.430000             23          1  0.9411765        \n",
            "pkdarabi/classification-of-travel-purpose                         Travel Ticket Cancellations for Risk Management       7656837  2023-08-15 17:23:58.320000           1001        100  0.9411765        \n",
            "mettag/mobile-price-classification                                Mobile Price Classification                             54382  2024-03-09 06:03:57.777000             26          6  0.23529412       \n",
            "tanujasreekanth/mobile-price-classifications                      mobile price classification                             72340  2022-10-11 17:53:46.850000             82          3  0.23529412       \n",
            "brandmustafa/phone-shop-dataset                                   phone shop dataset                                       2277  2025-09-07 03:16:53.807000            230         20  1.0              \n",
            "pratyushpuri/payment-card-fraud-detection-with-ml-models-2025     Payment Card Fraud Detection 2025                      650359  2025-08-13 14:57:29.880000           1406         28  1.0              \n",
            "kekosingh/mobile-price-classification                             Mobile Price Classification                            265522  2024-07-29 08:44:10.910000             33          1  0.4375           \n",
            "michaelmatta0/global-development-indicators-2000-2020             Global Development Analysis (2000-2020)               1311638  2025-05-11 16:57:19.013000           1774         32  1.0              \n",
            "tanujasreekanth/mobile-price-classification                       mobile price classification                             47366  2022-10-11 17:42:14.457000             38          3  0.11764706       \n",
            "madelinsarahp/mobile-price-prediction-with-classification         Mobile Price Prediction With Classification             71922  2022-06-23 04:41:56.893000            124          2  0.29411766       \n",
            "ashiskumarbera/flipkar-5g-mobile-phone-exctracted-data            Flipkar_5G_Mobile_Phone_Exctracted_data                 23011  2023-10-16 05:26:43.560000            142          7  1.0              \n",
            "oluwademiladeadeniyi/mtn-nigeria-customer-churn                   MTN Nigeria Customer Churn                              21537  2025-04-13 17:05:50.570000           1646         33  1.0              \n",
            "maham9/mobile-price-classification                                Mobile Price Classification                             12946  2025-07-20 15:00:10.523000              8          1  0.23529412       \n",
            "pratyushpuri/qsr-pos-logs-hotel-menu-modifiers-and-dayparts-2025  Hotel Menu Modifiers Sales Data QSR POS Logs 2025      288054  2025-08-09 08:07:19.007000            486         15  1.0              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d iabhishekofficial/mobile-price-classification\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpoEYwigbBrv",
        "outputId": "8688ab6f-42d0-40ef-dbb1-d75ae852fd05"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/iabhishekofficial/mobile-price-classification\n",
            "License(s): unknown\n",
            "Downloading mobile-price-classification.zip to /content\n",
            "  0% 0.00/70.6k [00:00<?, ?B/s]\n",
            "100% 70.6k/70.6k [00:00<00:00, 222MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/mobile-price-classification.zip\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJYsGi2ebGUI",
        "outputId": "b82619f5-0cb7-45cb-ea7c-0b0f1d12bddd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/mobile-price-classification.zip\n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Cargar los datos\n",
        "train = pd.read_csv(\"train.csv\")\n",
        "test = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Ver las primeras filas del train\n",
        "print(train.head())\n",
        "\n",
        "# Ver información general\n",
        "print(train.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2z0ykvgfbQAI",
        "outputId": "d59fda5c-226a-4d09-9a69-b312f0251fb5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  m_dep  \\\n",
            "0            842     0          2.2         0   1       0           7    0.6   \n",
            "1           1021     1          0.5         1   0       1          53    0.7   \n",
            "2            563     1          0.5         1   2       1          41    0.9   \n",
            "3            615     1          2.5         0   0       0          10    0.8   \n",
            "4           1821     1          1.2         0  13       1          44    0.6   \n",
            "\n",
            "   mobile_wt  n_cores  ...  px_height  px_width   ram  sc_h  sc_w  talk_time  \\\n",
            "0        188        2  ...         20       756  2549     9     7         19   \n",
            "1        136        3  ...        905      1988  2631    17     3          7   \n",
            "2        145        5  ...       1263      1716  2603    11     2          9   \n",
            "3        131        6  ...       1216      1786  2769    16     8         11   \n",
            "4        141        2  ...       1208      1212  1411     8     2         15   \n",
            "\n",
            "   three_g  touch_screen  wifi  price_range  \n",
            "0        0             0     1            1  \n",
            "1        1             1     0            2  \n",
            "2        1             1     0            2  \n",
            "3        1             0     0            2  \n",
            "4        1             1     0            1  \n",
            "\n",
            "[5 rows x 21 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2000 entries, 0 to 1999\n",
            "Data columns (total 21 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   battery_power  2000 non-null   int64  \n",
            " 1   blue           2000 non-null   int64  \n",
            " 2   clock_speed    2000 non-null   float64\n",
            " 3   dual_sim       2000 non-null   int64  \n",
            " 4   fc             2000 non-null   int64  \n",
            " 5   four_g         2000 non-null   int64  \n",
            " 6   int_memory     2000 non-null   int64  \n",
            " 7   m_dep          2000 non-null   float64\n",
            " 8   mobile_wt      2000 non-null   int64  \n",
            " 9   n_cores        2000 non-null   int64  \n",
            " 10  pc             2000 non-null   int64  \n",
            " 11  px_height      2000 non-null   int64  \n",
            " 12  px_width       2000 non-null   int64  \n",
            " 13  ram            2000 non-null   int64  \n",
            " 14  sc_h           2000 non-null   int64  \n",
            " 15  sc_w           2000 non-null   int64  \n",
            " 16  talk_time      2000 non-null   int64  \n",
            " 17  three_g        2000 non-null   int64  \n",
            " 18  touch_screen   2000 non-null   int64  \n",
            " 19  wifi           2000 non-null   int64  \n",
            " 20  price_range    2000 non-null   int64  \n",
            "dtypes: float64(2), int64(19)\n",
            "memory usage: 328.3 KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ver las primeras filas del train\n",
        "print(test.head())\n",
        "\n",
        "# Ver información general\n",
        "print(test.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEGO9Rjpc9ge",
        "outputId": "78fbb02d-b43e-4c96-c499-062e11c62419"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id  battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  \\\n",
            "0   1           1043     1          1.8         1  14       0           5   \n",
            "1   2            841     1          0.5         1   4       1          61   \n",
            "2   3           1807     1          2.8         0   1       0          27   \n",
            "3   4           1546     0          0.5         1  18       1          25   \n",
            "4   5           1434     0          1.4         0  11       1          49   \n",
            "\n",
            "   m_dep  mobile_wt  ...  pc  px_height  px_width   ram  sc_h  sc_w  \\\n",
            "0    0.1        193  ...  16        226      1412  3476    12     7   \n",
            "1    0.8        191  ...  12        746       857  3895     6     0   \n",
            "2    0.9        186  ...   4       1270      1366  2396    17    10   \n",
            "3    0.5         96  ...  20        295      1752  3893    10     0   \n",
            "4    0.5        108  ...  18        749       810  1773    15     8   \n",
            "\n",
            "   talk_time  three_g  touch_screen  wifi  \n",
            "0          2        0             1     0  \n",
            "1          7        1             0     0  \n",
            "2         10        0             1     1  \n",
            "3          7        1             1     0  \n",
            "4          7        1             0     1  \n",
            "\n",
            "[5 rows x 21 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 21 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   id             1000 non-null   int64  \n",
            " 1   battery_power  1000 non-null   int64  \n",
            " 2   blue           1000 non-null   int64  \n",
            " 3   clock_speed    1000 non-null   float64\n",
            " 4   dual_sim       1000 non-null   int64  \n",
            " 5   fc             1000 non-null   int64  \n",
            " 6   four_g         1000 non-null   int64  \n",
            " 7   int_memory     1000 non-null   int64  \n",
            " 8   m_dep          1000 non-null   float64\n",
            " 9   mobile_wt      1000 non-null   int64  \n",
            " 10  n_cores        1000 non-null   int64  \n",
            " 11  pc             1000 non-null   int64  \n",
            " 12  px_height      1000 non-null   int64  \n",
            " 13  px_width       1000 non-null   int64  \n",
            " 14  ram            1000 non-null   int64  \n",
            " 15  sc_h           1000 non-null   int64  \n",
            " 16  sc_w           1000 non-null   int64  \n",
            " 17  talk_time      1000 non-null   int64  \n",
            " 18  three_g        1000 non-null   int64  \n",
            " 19  touch_screen   1000 non-null   int64  \n",
            " 20  wifi           1000 non-null   int64  \n",
            "dtypes: float64(2), int64(19)\n",
            "memory usage: 164.2 KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Cargar train\n",
        "train = pd.read_csv(\"train.csv\")\n",
        "\n",
        "# Crear columna binaria: 0 = barato, 1 = caro\n",
        "# Por ejemplo, price_range 0 y 1 → barato (0), 2 y 3 → caro (1)\n",
        "train['price_binary'] = train['price_range'].apply(lambda x: 0 if x <= 1 else 1)\n",
        "\n",
        "# Revisar distribución\n",
        "print(train['price_binary'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkSp9Izbc8Ty",
        "outputId": "9449f1ea-5742-4021-9e03-62670bd8ecf6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "price_binary\n",
            "0    1000\n",
            "1    1000\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEd9DyRFdV9S",
        "outputId": "0f8f9af9-85fa-43d9-bb32-ebd2b8d5c082"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  m_dep  \\\n",
            "0            842     0          2.2         0   1       0           7    0.6   \n",
            "1           1021     1          0.5         1   0       1          53    0.7   \n",
            "2            563     1          0.5         1   2       1          41    0.9   \n",
            "3            615     1          2.5         0   0       0          10    0.8   \n",
            "4           1821     1          1.2         0  13       1          44    0.6   \n",
            "\n",
            "   mobile_wt  n_cores  ...  px_width   ram  sc_h  sc_w  talk_time  three_g  \\\n",
            "0        188        2  ...       756  2549     9     7         19        0   \n",
            "1        136        3  ...      1988  2631    17     3          7        1   \n",
            "2        145        5  ...      1716  2603    11     2          9        1   \n",
            "3        131        6  ...      1786  2769    16     8         11        1   \n",
            "4        141        2  ...      1212  1411     8     2         15        1   \n",
            "\n",
            "   touch_screen  wifi  price_range  price_binary  \n",
            "0             0     1            1             0  \n",
            "1             1     0            2             1  \n",
            "2             1     0            2             1  \n",
            "3             0     0            2             1  \n",
            "4             1     0            1             0  \n",
            "\n",
            "[5 rows x 22 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train['price_range'].unique())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Np_zKNFQdX6q",
        "outputId": "5c9d8207-8a36-4c8b-b47e-3d3749b2e6b2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 2 3 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Separar X e y\n",
        "X = train.drop(columns=['price_range','price_binary'])\n",
        "y = train['price_binary']\n",
        "\n",
        "# Dividir en train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Entrenar árbol\n",
        "model = DecisionTreeClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluar\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rTpOUNzeogP",
        "outputId": "5cd50aea-6d6a-4d08-f415-5acbba847e0b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.94\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Guardar el modelo entrenado\n",
        "with open(\"tree_model.pkl\", \"wb\") as f:\n",
        "    pickle.dump(model, f)\n"
      ],
      "metadata": {
        "id": "tlIJxFTcfApf"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "# 1️⃣ Cargar modelo entrenado\n",
        "with open(\"tree_model.pkl\", \"rb\") as f:\n",
        "    model = pickle.load(f)\n",
        "\n",
        "# 2️⃣ Cargar test.csv\n",
        "test = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# 3️⃣ Crear un diccionario para acceder rápido por id\n",
        "test_indexed = test.set_index('id')\n",
        "\n",
        "# 4️⃣ Programa interactivo\n",
        "while True:\n",
        "    try:\n",
        "        user_input = input(\"Ingresa el ID del móvil (o 'salir' para terminar): \")\n",
        "        if user_input.lower() == 'salir':\n",
        "            print(\"Programa terminado.\")\n",
        "            break\n",
        "\n",
        "        mobile_id = int(user_input)\n",
        "\n",
        "        if mobile_id not in test_indexed.index:\n",
        "            print(\"ID no encontrado. Intenta de nuevo.\")\n",
        "            continue\n",
        "\n",
        "        # Tomar los datos del móvil y eliminar columnas que no usamos\n",
        "        X_mobile = test_indexed.loc[[mobile_id]].drop(columns=[])\n",
        "\n",
        "        # Predecir\n",
        "        pred = model.predict(X_mobile)[0]\n",
        "\n",
        "        # Mostrar resultado\n",
        "        clase = \"Barato\" if pred == 0 else \"Caro\"\n",
        "        print(f\"El móvil con ID {mobile_id} se clasifica como: {clase}\\n\")\n",
        "\n",
        "    except ValueError:\n",
        "        print(\"Entrada no válida. Ingresa un número de ID.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8y31AnnYfGt4",
        "outputId": "368216cd-063f-4950-9f4b-a384ec61d44b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ingresa el ID del móvil (o 'salir' para terminar): 1\n",
            "El móvil con ID 1 se clasifica como: Caro\n",
            "\n",
            "Ingresa el ID del móvil (o 'salir' para terminar): 3\n",
            "El móvil con ID 3 se clasifica como: Caro\n",
            "\n",
            "Ingresa el ID del móvil (o 'salir' para terminar): 5\n",
            "El móvil con ID 5 se clasifica como: Barato\n",
            "\n",
            "Ingresa el ID del móvil (o 'salir' para terminar): salir\n",
            "Programa terminado.\n"
          ]
        }
      ]
    }
  ]
}